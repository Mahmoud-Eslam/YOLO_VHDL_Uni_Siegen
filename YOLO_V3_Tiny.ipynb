{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d45af627-3dad-40f1-9252-a367c26804c1",
   "metadata": {},
   "source": [
    "# Training Custom YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d58eb8d-a351-4582-8f3f-9163ca502363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.models.detection import yolov3_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383d74ca-fa53-46e3-8666-a1ab8366de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = yolov3_tiny(pretrained=False)\n",
    "\n",
    "model.load_state_dict(torch.load('yolov3-tiny.weights'))\n",
    "\n",
    "num_classes = 80  \n",
    "model.classifier[6] = nn.Linear(1024, num_classes)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "train_dataset = CocoDetection(root='/path/to/coco/', annFile='/path/to/coco/annotations/instances_train2014.json', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "epochs = 10  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n",
    "\n",
    "torch.save(model.state_dict(), 'yolov3_tiny_custom.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dda9ae-d2fc-4f75-9e2f-5b25853ddf11",
   "metadata": {},
   "source": [
    "# Extracting Weights and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c01b49-e948-4850-8334-d79d61c01146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdf2bd6-ba2c-497f-92f0-c2706f1d6d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_path = 'yolov3-tiny.h5'\n",
    "loaded_model = tf.keras.models.load_model(keras_model_path)\n",
    "\n",
    "weights = loaded_model.get_weights()\n",
    "\n",
    "for i, layer_weights in enumerate(weights):\n",
    "    filename = f'layer_{i}_weights.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        for weight in layer_weights.flatten():\n",
    "            file.write(f'{weight}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca3a954-f79d-4b9d-a462-3e07a4c2e21f",
   "metadata": {},
   "source": [
    "# Test Image and Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84962b89-941a-435b-a020-6dbce4c3cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_d_im = np.array([[[1,2,3],[4,5,6],[7,8,9],[10,11,12],[13,14,15]],\n",
    "                      [[16,17,18],[19,20,21],[22,23,24],[25,26,27],[28,29,30]],\n",
    "                      [[-31,-32,-33],[-34,-35,-36],[37,38,39],[40,42,42],[43,44,45]],\n",
    "                      [[-46,-47,-48],[-49,-50,-51],[52,53,54],[55,56,57],[58,59,60]],\n",
    "                      [[-61,-62,-63],[-64,-65,-66],[67,68,69],[70,71,72],[73,74,75]] \n",
    "                      ])\n",
    "three_d_kernel = np.array([\n",
    "                          [[1, 2, 1],[2, 1, 2],[1, 2, 1]],\n",
    "                          [[1, 2, 1],[2, 1, 2],[1, 2, 1]],\n",
    "                          [[1, 2, 1],[2, 1, 2],[1, 2, 1]]\n",
    "                          ])\n",
    "print(three_d_im.shape)\n",
    "print(three_d_kernel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756c21df-6c5f-431f-99bb-b946768297b7",
   "metadata": {},
   "source": [
    "# Check array dimentions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea13fa8-02a6-44f2-a4ce-efe9344cd7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_d_i = np.array([[[1,2,3],[4,5,6],[7,8,9],[10,11,12]],\n",
    "                      [[16,17,18],[19,20,21],[22,23,24],[25,26,27]],\n",
    "                      [[-31,-32,-33],[-34,-35,-36],[37,38,39],[40,42,42]],\n",
    "                      [[-46,-47,-48],[-49,-50,-51],[52,53,54],[55,56,57]],\n",
    "                      [[-61,-62,-63],[-64,-65,-66],[67,68,69],[70,71,72]] \n",
    "                      ])\n",
    "print(three_d_i.shape)\n",
    "height, width, depth  = three_d_i.shape\n",
    "print(height)\n",
    "print(three_d_i[1,2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3866ffd7-be71-4555-9b87-d8773cc2a63f",
   "metadata": {},
   "source": [
    "# Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82187728-6f0a-4682-98d9-2e7817a7813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_d_conv_one_filter(img,kernel):\n",
    "    im_dimensions = img.shape\n",
    "    kernel_dimensions = kernel.shape\n",
    "\n",
    "    n_i_height =  (im_dimensions[0] - kernel_dimensions[0]) + 1 \n",
    "    n_i_width  =  (im_dimensions[1] - kernel_dimensions[1]) + 1\n",
    "    n_i_depth  =  (im_dimensions[2] - kernel_dimensions[2]) + 1\n",
    "\n",
    "    k_height = kernel_dimensions[0]\n",
    "    k_width  = kernel_dimensions[1]\n",
    "    k_depth  = kernel_dimensions[2]\n",
    "    \n",
    "    new_img = np.zeros((n_i_height, n_i_width, n_i_depth), dtype=img.dtype)\n",
    "\n",
    "    for d in range(n_i_depth):\n",
    "        for h in range(n_i_height):\n",
    "            for w in range(n_i_width):\n",
    "                conv_sum = 0\n",
    "                for k_d in range(k_depth):\n",
    "                    for k_h in range(k_height):\n",
    "                        for k_w in range(k_width):\n",
    "                            conv_sum += img[(h + k_h), (w + k_w), (d + k_d)] * kernel[k_h, k_w, k_d]\n",
    "                new_img[h, w, d] = conv_sum      \n",
    "                                                      \n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2da42df-d946-4eca-96ef-75708b346b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_result = three_d_conv_one_filter(three_d_i,three_d_kernel)\n",
    "print(conv_result.shape,\"\\n\\n\", conv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4164d371-5787-479c-8b8f-11845cb95b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_d_conv(img,kernel):\n",
    "    im_dimensions = img.shape\n",
    "    kernel_dimensions = kernel.shape\n",
    "\n",
    "    k_height  = kernel_dimensions[0]\n",
    "    k_width   = kernel_dimensions[1]\n",
    "    k_depth   = kernel_dimensions[2]\n",
    "    k_filters = kernel_dimensions[3]\n",
    "\n",
    "    n_i_height =  (im_dimensions[0] - kernel_dimensions[0]) + 1 \n",
    "    n_i_width  =  (im_dimensions[1] - kernel_dimensions[1]) + 1\n",
    "    n_i_depth  =  (im_dimensions[2] - kernel_dimensions[2]) + 1\n",
    "\n",
    "    new_img = np.zeros((n_i_height, n_i_width, k_filters), dtype=img.dtype)\n",
    "    \n",
    "    for d in range(n_i_depth): # -->> this will be performed only once but I will leave it to be more generic\n",
    "        for h in range(n_i_height):\n",
    "            for w in range(n_i_width):\n",
    "                for k_f in range(k_filters):\n",
    "                    conv_sum = 0\n",
    "                    for k_d in range(k_depth):\n",
    "                        for k_h in range(k_height):\n",
    "                            for k_w in range(k_width):\n",
    "                                conv_sum += img[(h + k_h), (w + k_w), (d + k_d)] * kernel[k_h, k_w, k_d, k_f]\n",
    "                    new_img[h, w, k_f] = conv_sum      \n",
    "                                                      \n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89017d5-9b0a-470c-b799-78770d6d27e5",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3266c6-66af-4e07-8d88-a91855e377b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchNorm(img,gamma,beta,mean,variance):\n",
    "    epsilon = 0.001\n",
    "    height, width, depth = img.shape \n",
    "    \n",
    "    new_img = np.zeros((height, width, depth), dtype=img.dtype)\n",
    "    \n",
    "    for h in range(height):\n",
    "        for w in range(width):\n",
    "            for d in range(depth):\n",
    "                x = img[h,w,d]\n",
    "                x_norm = (x - mean[d]) / np.sqrt(variance[d] + epsilon)\n",
    "                y = (gamma[d] * x_norm) + beta[d]\n",
    "                new_img[w,h,d] = y\n",
    "    return new_img            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f72db6c-d3e3-4da9-a37a-8d9fcb840e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "gamma = np.array([0.5, 1.5])\n",
    "beta = np.array([-0.5, 0.5])\n",
    "mean = np.array([2.0, 4.0])\n",
    "variance = np.array([1.5, 2.5])\n",
    "\n",
    "batchNorm_res = batchNorm(image,gamma,beta,mean,variance)\n",
    "print(batchNorm_res.shape,\"\\n\",batchNorm_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c563a063-f197-47a4-aafa-5c7228e3caa7",
   "metadata": {},
   "source": [
    "# LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8042a580-5e5a-47ee-ad7a-ac6b6819e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Leaky_ReLU(img):\n",
    "    im_shape = img.shape\n",
    "    new_img = np.zeros((im_shape[0], im_shape[1], im_shape[2]), dtype=int)\n",
    "    \n",
    "    for d in range(im_shape[2]):\n",
    "        for h in range(im_shape[0]):\n",
    "            for w in range(im_shape[1]):\n",
    "               if(img[h,w,d] > 0):\n",
    "                   new_img[h,w,d] = img[h,w,d]\n",
    "               else:\n",
    "                   new_img[h,w,d] = -0.01 * img[h,w,d]\n",
    "                \n",
    "    return new_img    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a862e46-abbb-4ae1-bbae-7a6bf4552936",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_result = Leaky_ReLU(conv_result)\n",
    "print(act_result.shape,\"\\n\\n\", act_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa83f6-7c9e-440d-8594-ae5996a830a0",
   "metadata": {},
   "source": [
    "# MaxPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73862a8-13f7-411e-9870-7189be22ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool_three_d_image(img, stride):\n",
    "    height, width, depth = img.shape\n",
    "    pooled_height = height // stride\n",
    "    pooled_width = width // stride\n",
    "\n",
    "    output_image = np.zeros((pooled_height, pooled_width, depth), dtype=img.dtype)\n",
    "\n",
    "    for d in range(depth):\n",
    "        for h in range(0,height - 1,stride):\n",
    "            for w in range(0,width - 1,stride):\n",
    "                \n",
    "                max_val = img[h,w,d]\n",
    "                \n",
    "                if(img[h,w+1,d] > max_val):\n",
    "                    max_val = img[h,w+1,d]\n",
    "                if(img[h+1,w,d] > max_val):\n",
    "                    max_val = img[h+1,w,d]\n",
    "                if(img[h+1,w+1,d]>max_val):    \n",
    "                    max_val = img[h+1,w+1,d]\n",
    "                    \n",
    "                output_image[h // stride, w // stride, d] = max_val\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2b9d6f-0aba-43e3-95bc-1e1ac6805eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.array([\n",
    "    [[1], [2], [3], [4], [17]],\n",
    "    [[5], [6], [7], [8], [18]],\n",
    "    [[9], [10], [11], [12],[19]],\n",
    "    [[13], [14], [15], [16],[20]],\n",
    "    [[1], [100], [0], [18],[21]]\n",
    "], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199fb149-d342-4099-bed6-a222d10eacca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_image.shape)\n",
    "maxpool_res = maxpool_three_d_image(test_image,2)\n",
    "print(maxpool_res.shape,\"\\n\\n\",maxpool_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c11925e-ca72-4b4d-8b97-802da8cc91df",
   "metadata": {},
   "source": [
    "# Up sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f72910c-01cb-4b43-aa0c-22b115f0f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_three_d_image(img, stride):\n",
    "    \n",
    "    width,height,depth = img.shape\n",
    "    upscaled_height = height * stride\n",
    "    upscaled_width = width * stride\n",
    "\n",
    "    output_image = np.zeros((upscaled_width, upscaled_height, depth), dtype=img.dtype)\n",
    "\n",
    "    for d in range(depth):\n",
    "        for h in range(upscaled_height):\n",
    "            for w in range(upscaled_width):\n",
    "                original_h = h // stride\n",
    "                original_w = w // stride\n",
    "\n",
    "                output_image[w, h, d] = img[original_w, original_h, d]\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7970a43c-b910-49f4-8c2f-691788171e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsample_result = upsample_three_d_image(act_result, 2)\n",
    "print(upsample_result.shape,\"\\n\\n\", upsample_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace655e3-29d2-4a04-bcdf-813546bb5f19",
   "metadata": {},
   "source": [
    "# Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db962504-1d43-4d9a-9043-10ec9d464c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Concatenation(conv1, conv2):\n",
    "    width1,height1,depth1 = conv1.shape\n",
    "    width2,height2,depth2 = conv2.shape\n",
    "    \n",
    "    output_image = np.zeros((width1, height1, (depth1 + depth2)), dtype=conv1.dtype)\n",
    "\n",
    "    for d in range(depth1):\n",
    "        for h in range(height1):\n",
    "            for w in range(width1):\n",
    "                output_image[w,h,d] = conv1[w,h,d]\n",
    "\n",
    "    for d in range(depth2):\n",
    "        for h in range(height2):\n",
    "            for w in range(width2):\n",
    "                output_image[w,h,d + depth1] = conv2[w,h,d] \n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b1175-6761-4ba0-9989-c1d1a2501d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_res = Concatenation(test_image,test_image)\n",
    "print(concat_res.shape,\"\\n\",concat_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d907c70a-1802-4437-a917-8cc5d7deb4a4",
   "metadata": {},
   "source": [
    "# YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68793c05-2cad-4ea6-8dcd-0c40ad677b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo(img, anchors, yolo_size, objectness_threshold):\n",
    "    height,width,depth = img.shape\n",
    "    anchor_height, anchor_width = anchors.shape\n",
    "    \n",
    "    yolo_anchors = np.zeros((anchor_height//2, anchor_width), dtype=anchors.dtype)\n",
    "    \n",
    "    if(yolo_size == 1):\n",
    "        for i in range(anchor_height // 2):\n",
    "            for j in range(anchor_width):\n",
    "                yolo_anchors[i,j] = anchors[i,j]\n",
    "    else:\n",
    "        for i in range(3, anchor_height):\n",
    "           for j in range(anchor_width):\n",
    "                yolo_anchors[i-3,j] = anchors[i,j]\n",
    "\n",
    "    img_width, img_height = 416, 416\n",
    "    cell_width = img_width/width \n",
    "    cell_height = img_height/height\n",
    "\n",
    "    detected_boxes = []\n",
    "    \n",
    "    for h in range(height):\n",
    "        for w in range(width):\n",
    "            for b in range(anchor_height // 2):\n",
    "                confidence = img[h,w,b * 2]\n",
    "                if(confidence > objectness_threshold):\n",
    "                    pred_x = img[h,w,(b * 2) + 1]\n",
    "                    pred_y = img[h,w,(b * 2) + 2]\n",
    "                    pred_width = img[h,w,(b * 2) + 3]\n",
    "                    pred_height = img[h,w,(b * 2) + 4] \n",
    "                    \n",
    "                    sigmoid_x = 1 / (1 + np.exp(-pred_x))\n",
    "                    sigmoid_y = 1 / (1 + np.exp(-pred_y))\n",
    "                    \n",
    "                    x_absolute = (w + sigmoid_x) * cell_width\n",
    "                    y_absolute = (h + sigmoid_y )* cell_height\n",
    "                    width_absolute = np.exp(pred_width) * yolo_anchors[b, 0]  \n",
    "                    height_absolute = np.exp(pred_height) * yolo_anchors[b, 1] \n",
    "\n",
    "                    detected_boxes.append([confidence, x_absolute, y_absolute, width_absolute, height_absolute, 1])\n",
    "                    \n",
    "    \n",
    "    return detected_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ce2cc3-cfe5-4ca1-afa7-15bcce39f520",
   "metadata": {},
   "source": [
    "# NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346d3fd5-e43a-4c4e-8cf8-c77db91209e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(detected_boxes,iou_threshold):\n",
    "    detected_boxes = np.array(detected_boxes)\n",
    "    # sorting the array\n",
    "    for i in range(len(detected_boxes) - 1):\n",
    "        for j in range(i + 1, len(detected_boxes)):\n",
    "            if detected_boxes[i][0] < detected_boxes[j][0]:\n",
    "                detected_boxes[i] = detected_boxes[j]\n",
    "                detected_boxes[j] = detected_boxes[i]\n",
    "\n",
    "    non_suppressed_boxes = []\n",
    "\n",
    "    # starting iou calculations \n",
    "    # 0 -> deleted\n",
    "    # 1 -> not chicked\n",
    "    # 2 -> checked and added\n",
    "    for i in range(len(detected_boxes)):\n",
    "        if(detected_boxes[i,5] == 1):\n",
    "            detected_boxes[i,5] = 2\n",
    "            for j in range(len(detected_boxes)):\n",
    "                if((j != i) and (detected_boxes[j,5] == 1)):\n",
    "                    x1, y1, w1, h1 = detected_boxes[i,0], detected_boxes[i,1], detected_boxes[i,2], detected_boxes[i,3]\n",
    "                    x2, y2, w2, h2 = detected_boxes[j,0], detected_boxes[j,1], detected_boxes[j,2], detected_boxes[j,3]\n",
    "\n",
    "                    x_intersection, y_intersection, w_intersection, h_intersection = 0, 0, 0, 0\n",
    "                    \n",
    "                    if(x1 > x2):\n",
    "                        x_intersection = x1\n",
    "                    else:\n",
    "                        x_intersection = x2\n",
    "                    if(y1 > y2):\n",
    "                        y_intersection = y1\n",
    "                    else:\n",
    "                        y_intersection = y2\n",
    "                    if((x1 + w1) < (x2 + w2)):\n",
    "                        w_intersection = (x1 + w1)\n",
    "                    else:\n",
    "                        w_intersection = (x2 + w2)\n",
    "                    if((w_intersection - x_intersection) < 0):\n",
    "                        w_intersection = 0\n",
    "                    if((y1 + h1) < (y2 + h2)):\n",
    "                        h_intersection = (y1 + h1)\n",
    "                    else:\n",
    "                        h_intersection = (y2 + h2)\n",
    "                    if((h_intersection - y_intersection) < 0):\n",
    "                        h_intersection = 0\n",
    "\n",
    "                    area_intersection = w_intersection * h_intersection\n",
    "                    area_box1 = w1 * h1\n",
    "                    area_box2 = w2 * h2\n",
    "                    area_union = area_box1 + area_box2 - area_intersection\n",
    "                    iou = area_intersection / (area_union + 1e-6) \n",
    "\n",
    "                    if(iou > iou_threshold):\n",
    "                        detected_boxes[j,5] = 0\n",
    "                        \n",
    "    for i in range(len(detected_boxes)):\n",
    "        if(detected_boxes[i,5] == 2):\n",
    "            non_suppressed_boxes.append(detected_boxes[i])\n",
    "\n",
    "    return non_suppressed_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde755de-d32d-4f3c-afed-15d992d21810",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.random.rand(13, 13, 255).astype(np.float32)\n",
    "anchors = np.array([10, 14, 23, 27, 37, 58, 81, 82, 135, 169, 344, 319]).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c82cf5d-79c7-4c93-959f-2741ef9284f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_res = yolo(image, anchors, 1, 0.5)\n",
    "yolo_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512ff550-607c-4a41-b26d-a2d4d3c80655",
   "metadata": {},
   "outputs": [],
   "source": [
    "nms_res = nms(yolo_res,0.7)\n",
    "print(len(yolo_res),len(nms_res))\n",
    "nms_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2970b2ed-3216-40a0-a39c-0a4a1fe11707",
   "metadata": {},
   "source": [
    "# Helper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c12e98-d829-450e-836d-23c04289ddbe",
   "metadata": {},
   "source": [
    "# Generate random 3d vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf219a9d-2b7c-4831-baec-41968ad50e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b77d92b-9747-4a57-84ef-bbd8630b323c",
   "metadata": {},
   "source": [
    "# 3D vector for image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7177fe90-a619-4109-a042-0c88467778fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_3d_vector(height, width, depth):\n",
    "    random_vector = np.random.uniform(0, 10, size=(height, width, depth))\n",
    "\n",
    "    return random_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a99ec8f-a11d-4df3-92ff-c4c95403ac55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random 3D Vector (shape: (32, 32, 3)):\n"
     ]
    }
   ],
   "source": [
    "height = 32\n",
    "width  = 32\n",
    "depth  = 3\n",
    "\n",
    "random_vector_32_32_3 = generate_random_3d_vector(height, width, depth)\n",
    "\n",
    "\n",
    "print(f\"Random 3D Vector (shape: {random_vector_32_32_3.shape}):\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68091923-339b-4c06-baaa-1bd9df209bb9",
   "metadata": {},
   "source": [
    "# 4D vectors for kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0445dcff-2759-4c5c-8afd-6bfcdbdf351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_4d_vector(height, width, depth, filters):\n",
    "    random_vector = np.random.uniform(0, 10, size=(height, width, depth, filters))\n",
    "\n",
    "    return random_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcbc394-c091-43b7-9e9e-a0d167060f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "krnl_height  = 3\n",
    "krnl_width   = 3\n",
    "krnl_depth   = 3\n",
    "krnl_filters = 16\n",
    "random_3d_vector_3_3_3_16 = generate_random_4d_vector(krnl_height, krnl_width, krnl_depth, krnl_filters)\n",
    "\n",
    "\n",
    "print(f\"Random 3D Vector (shape: {random_3d_vector_3_3_3_16.shape}):\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24cd9ee-53d3-4cbe-a49c-0fd180601bc7",
   "metadata": {},
   "source": [
    "# Store the vector in a file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b2fe97-93d0-4d76-8594-e5ea78a83c02",
   "metadata": {},
   "source": [
    "# 3D image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a7cf74-5d4a-4948-9e0c-dfb87cb2c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_vector_to_file(filename, vector):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(\"(\")\n",
    "        for i in range(vector.shape[0]):\n",
    "            if(i == 0):\n",
    "                file.write(\"(\")\n",
    "            else:\n",
    "                file.write(\"    (\")\n",
    "            for j in range(vector.shape[1]):\n",
    "                if(j < (vector.shape[1] - 1)):\n",
    "                    file.write(\"(\" + \", \".join(map(str, vector[i, j])) + \"), \")\n",
    "                else:\n",
    "                    file.write(\"(\" + \", \".join(map(str, vector[i, j])) + \")\")\n",
    "            if(i < (vector.shape[0] - 1)):\n",
    "                file.write(\"),\\n\")\n",
    "            else:\n",
    "                file.write(\")\")\n",
    "        file.write(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7db3c60-9445-4b18-a198-2ae414f97eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"random_vector_32_32_3.vhdl\"\n",
    "write_vector_to_file(filename, random_vector_32_32_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f234811-c150-422a-ac3f-be38150c7c2c",
   "metadata": {},
   "source": [
    "# 4D image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbea6f77-d1f8-49e3-b151-2f2d2ce852c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_vector_to_file(filename, vector):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(\"(\")\n",
    "        for i in range(vector.shape[0]):\n",
    "            if(i == 0):\n",
    "                file.write(\"(\")\n",
    "            else:\n",
    "                file.write(\"    (\")\n",
    "            for j in range(vector.shape[1]):\n",
    "                file.write(\"(\")\n",
    "                for k in range(vector.shape[2]):\n",
    "                    if(k < (vector.shape[2] - 1)):\n",
    "                        file.write(\"(\" + \", \".join(map(str, vector[i, j, k])) + \"), \")\n",
    "                    else:\n",
    "                        file.write(\"(\" + \", \".join(map(str, vector[i, j, k])) + \")\")\n",
    "                if(j < (vector.shape[1] - 1)):\n",
    "                    file.write(\"),\\n\")\n",
    "                else:\n",
    "                    file.write(\")\")        \n",
    "            if(i < (vector.shape[0] - 1)):\n",
    "                file.write(\"),\\n\")\n",
    "            else:\n",
    "                file.write(\")\")\n",
    "        file.write(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9493a21-5f33-4a0f-b376-d3866f05a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"random_vector_3_3_3_16.vhdl\"\n",
    "write_vector_to_file(filename, random_3d_vector_3_3_3_16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a47038f-d45d-4f7e-b7d4-b5f0c742ff7b",
   "metadata": {},
   "source": [
    "# Perform padding on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007b348a-f7a5-4268-a80f-9d18c899b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_3d_image(image, padding):\n",
    "\n",
    "    pad_height, pad_width, pad_depth = padding\n",
    "\n",
    "    padded_image = np.pad(image, ((pad_height, pad_height), (pad_width, pad_width), (pad_depth, pad_depth)), mode='constant')\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "image_shape = (2, 2, 3)\n",
    "image = np.random.random(image_shape)\n",
    "\n",
    "padding = (1, 0, 0)\n",
    "padded_image = pad_3d_image(image, padding)\n",
    "\n",
    "print(\"Original Image Shape:\", image.shape, \"\\n\", image)\n",
    "print(\"Padded Image Shape:\", padded_image.shape, \"\\n\", padded_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b063f-3f37-491d-8e49-a1d79ef2329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_vector_416_416_3.shape)\n",
    "print(random_3d_vector_3_3_16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7c7780-6152-4b9a-b36e-e09514d7e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = three_d_conv(random_vector_416_416_3, random_3d_vector_3_3_3_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ce9b5-9aea-4cae-9245-d84933c7d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_batch = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
